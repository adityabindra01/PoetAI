# PoetAI
This is a Public Repository for PoetAI, the limerick generator!

## Members:
> Aditya Bindra\
> Carnegie Mellon University\
> Pittsburgh, PA 15213\
> bindra@cmu.edu

> Aditya Malani\
> Carnegie Mellon University\
> Pittsburgh, PA 15213\
> amalani2@andrew.cmu.edu

> Nirmalsing Patil\
> Carnegie Mellon University\
> Pittsburgh, PA 15213\
> nirmalsp@andrew.cmu.edu

> Bandish Parikh\
> Carnegie Mellon University\
> Pittsburgh, PA 15213\
> bparikh@andrew.cmu.edu

## 1. Introduction
Poetry is an outcome of creation. It is a form of literary work that is often characterized by an interplay of thought-provoking words meant to stimulate the human mind. A limerick is a short humorous form of verse that has five lines and follows the AABBA rhyme scheme.\
\
What if we could use ‘art’-ificial intelligence to create art? While a lot of research has been done in the field of Natural Language Understanding, the area pertaining to generation and qualitative analysis of poetry still remains to be explored. Even after much research, AI has been criticized for lacking creativity and for occasionally producing texts that make no sense. The expected output in this case isn’t a simple numerical value or a class label, but rather an art piece that is meant to be creative, expressive, and appealing to humans.\
\
We derived that, in the context of an Artificial Intelligence algorithm, creativity is just the development of clearly stated mathematical objective functions that a model must be optimized on. The desired output of creativity can not be captured by conventional loss functions. Our main objective is to respond to the question, "What makes this piece of poetry/limerick a good one?" while giving objective functions to grade a specific piece of poetry/limerick. Will a large language model be able to learn the art of poetry? In this project we used 4 models - GPT2 for limerick generation, LSTM based rhyme scorer for evaluating the rhyming scheme of the limerick, pretrained sentence transformer model MiniLM-L6-V2 for evaluating context of the limericks and BERT for fixing the rhyme of a limerick with a good context score.

## 2. Literature Review
### 2.1. GPoet-2 : GPT2 based transformer with forward and reverse fine tuning
A great work that we referenced is GPoeT-2: A GPT-2 Based Poem Generator [6], where the authors propose a two-stage free-form limerick generation. The proposed two-stage generation uses the forward language model to generate a limerick’s first line with high quality and diversity, then uses the reverse language model to generate the rest of the four lines given the first line generated by forwarding LM. They also select and evaluate a few metrics that quantify the idea of “good poetry”
such as syntactical correctness, lexical diversity, and subject/topic consistency.

### 2.2. LimGen : GPT2 based limerick generator
This is another amazing work we referenced, which uses Search Metrics to enforce rhyme. This is one of the more recent works by Jianyou Wang et al.[8] where they use search metrics such as the Adaptive Multi-Templated Constraint algorithm that constrains their search to the space of realistic poems, the Multi-Templated Beam
Search algorithm which searches efficiently through the space, and the probabilistic story-line algorithm that aims to provide coherent story-lines related to a user-provided prompt word.

### 2.3. Deep-Speare : RNN based Sonnet generator with rhyming dictionary to enforce rhyming
Deep-speare[17] is a Sonnet based model used to capture language, rhyming and meter of poetry. These models under-performed in generating human level poetry but served as good reference for rhyme capture with models. Rhyme was enforced by a cosine similarity of the last words generated by the model and a loss function was employed to penalize model when it was not rhyming. A rhyming dictionary was maintained to pick words based on the context.
